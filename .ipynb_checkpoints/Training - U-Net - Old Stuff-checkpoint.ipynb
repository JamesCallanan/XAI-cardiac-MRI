{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim\n",
    "import os\n",
    "import numpy as np\n",
    "from time import time\n",
    "from torch.optim import lr_scheduler\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Framework:\n",
    "    def __init__(self, model, loss, lr=1e-3):\n",
    "        self.model = model\n",
    "        self.loss = loss\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(params=self.model.parameters(), lr=self.lr)\n",
    "        if torch.cuda.is_available():\n",
    "            self.model = model.cuda()\n",
    "            self.loss = loss.cuda()\n",
    "\n",
    "    def optimize(self, X, y):\n",
    "        y_pred = self.model.forward(X)\n",
    "        loss = self.loss(y, y_pred)\n",
    "        return loss, y_pred\n",
    "\n",
    "    def backwardpass(self, loss):\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "    def save(self, path):\n",
    "        torch.save(self.model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(framework, gen_loaders, n_epochs, params):\n",
    "\n",
    "    if params[\"checkpoint_file\"] == \"none\":\n",
    "        resume_run = False\n",
    "        experiment_dir = os.path.join(params[\"save_dir\"], params[\"experiment_name\"])\n",
    "        train_dir = os.path.join(experiment_dir, f'training')\n",
    "\n",
    "        if not os.path.exists(train_dir):\n",
    "            os.makedirs(train_dir)\n",
    "        if os.listdir(train_dir):\n",
    "            raise IOError('train_dir is expected to be empty for new experiments. '\n",
    "                          f'{train_dir} is not empty! Aborting...')\n",
    "\n",
    "        # determine backup folder path and create it if necessary\n",
    "        backup_dir = os.path.join(\n",
    "            params[\"backup_dir\"],\n",
    "            os.path.split(os.path.normpath(train_dir))[1]\n",
    "        )\n",
    "        # create the backup dir for storing validation best snapshots\n",
    "        if not os.path.exists(backup_dir):\n",
    "            os.makedirs(backup_dir)\n",
    "\n",
    "        # save command-line arguments to train and backup dir\n",
    "        json.dump(params, open(os.path.join(train_dir, 'params.json'), 'w'),\n",
    "                  indent=4, sort_keys=True)\n",
    "        json.dump(params, open(os.path.join(backup_dir, 'params.json'), 'w'),\n",
    "                  indent=4, sort_keys=True)\n",
    "\n",
    "        log_file = os.path.join(train_dir, \"log_file.log\")\n",
    "        my_log = open(log_file, 'w')\n",
    "        my_log.write(\"Starting training\")\n",
    "        my_log.close()\n",
    "\n",
    "\n",
    "    else:\n",
    "        resume_run = True\n",
    "        train_dir = os.path.split(params[\"checkpoint_file\"])[0]\n",
    "\n",
    "        # load checkpoint and corresponding args.json overwriting command-line args\n",
    "        checkpoint_file = params[\"checkpoint_file\"]  # backup checkpoint file path\n",
    "        params = json.load(open(os.path.join(train_dir, 'params.json')))\n",
    "        backup_dir = os.path.join(params[\"backup_dir\"],\n",
    "                                  os.path.split(os.path.normpath(train_dir))[1])\n",
    "        log_file = os.path.join(train_dir, \"log_file.log\")\n",
    "\n",
    "    train_opts = params[\"train_opts\"]\n",
    "    if train_opts[\"verbose\"]:\n",
    "        print(f'using training directory {train_dir}')\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    framework.model.to(device)\n",
    "\n",
    "    if train_opts[\"parallelize\"]:\n",
    "        device_ids = list(range(torch.cuda.device_count()))\n",
    "        framework.model = nn.DataParallel(framework.model, device_ids=device_ids)\n",
    "\n",
    "    tic = time()\n",
    "    n_early_stopping = 0\n",
    "    val_history = {'loss': [], 'mean_IoU': []}\n",
    "    train_history = {'loss': []}\n",
    "\n",
    "    scheduler = lr_scheduler.StepLR(framework.optimizer, step_size=train_opts[\"scheduler_step_size\"], gamma=train_opts[\"scheduler_gamma\"])\n",
    "\n",
    "    stats = {\n",
    "        'train_losses': [], 'train_losses_epochs': [],\n",
    "        'val_losses': [], 'val_ious': [], 'val_ious_epochs': [],\n",
    "        'best_val_iou': 0., 'best_val_epoch': 0.,\n",
    "        'resume_epochs': []\n",
    "    }\n",
    "\n",
    "    if resume_run:\n",
    "        if train_opts[\"verbose\"]:\n",
    "            print('resuming training...')\n",
    "\n",
    "        # load epoch, step, state_dict of model, optimizer as well as best val\n",
    "        # acc and step\n",
    "        checkpoint = torch.load(checkpoint_file)\n",
    "        resume_epoch = checkpoint['epoch']\n",
    "        framework.model.load_state_dict(checkpoint['model'])\n",
    "        framework.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "\n",
    "        stats['train_losses'] = checkpoint['train_losses']\n",
    "        stats['train_losses_epochs'] = checkpoint['train_losses_epochs']\n",
    "        stats['val_losses'] = checkpoint['val_losses']\n",
    "        stats['val_ious'] = checkpoint['val_ious']\n",
    "        stats['val_ious_epochs'] = checkpoint['val_ious_epochs']\n",
    "        stats['best_val_iou'] = checkpoint['best_val_iou']\n",
    "        stats['best_val_epoch'] = checkpoint['best_val_epoch']\n",
    "        stats['resume_epochs'] = checkpoint['resume_epochs']\n",
    "        stats['resume_epochs'].append(resume_epoch)\n",
    "\n",
    "\n",
    "    else:\n",
    "        if train_opts[\"verbose\"]:\n",
    "            print('starting training!')\n",
    "        resume_epoch = 0\n",
    "\n",
    "    saver = CheckpointSaver(save_dir=train_dir,\n",
    "                            backup_dir=backup_dir)\n",
    "\n",
    "    for i in range(resume_epoch, n_epochs):\n",
    "        my_log = open(log_file, 'a+')\n",
    "        my_log.write(\"\\n***************\")\n",
    "        if train_opts[\"verbose\"]:\n",
    "            print(\"**************\")\n",
    "        for phase in ['train', 'val']:\n",
    "            epoch_loss = 0.0\n",
    "            val_meanIoU = 0.0\n",
    "            n_iter = 0\n",
    "            if phase == 'train':\n",
    "                framework.model.train()\n",
    "            else:\n",
    "                framework.model.eval()\n",
    "            for _, (X, y, lat, long) in gen_loaders[phase]():\n",
    "                if train_opts[\"data_augmentation\"]:\n",
    "                    #Duke scheme for augmentation\n",
    "                    X, y = augment.random_duke_augmentation(X, y)\n",
    "                if params[\"model_opts\"][\"model\"] != \"fusionnet\":\n",
    "                    y = y[:,:,92:params[\"patch_size\"]-92,92:params[\"patch_size\"]-92]\n",
    "                if torch.cuda.is_available():\n",
    "                    X = X.cuda()\n",
    "                    y = y.cuda()\n",
    "                framework.optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    y_pred = framework.model.forward(X)\n",
    "                    loss = framework.loss(torch.squeeze(y,1).long(), y_pred)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        framework.optimizer.step()\n",
    "                n_iter += 1\n",
    "                epoch_loss += loss.item()\n",
    "                if phase == 'val':\n",
    "                    y = np.squeeze(y.cpu().numpy(), axis=1)\n",
    "                    batch_size, _, _ = y.shape\n",
    "                    y_hat = y_pred.cpu().numpy()\n",
    "                    y_hat = np.argmax(y_hat, axis=1)\n",
    "                    batch_meanIoU=0\n",
    "                    for j in range(batch_size):\n",
    "                        batch_meanIoU += mean_IoU(y_hat[j], y[j])\n",
    "                    batch_meanIoU /= batch_size\n",
    "                    val_meanIoU += batch_meanIoU\n",
    "\n",
    "            # save if notice improvement\n",
    "            epoch_loss /= n_iter\n",
    "            loss_str = \"\\n{} loss: {} Epoch number: {} time: {}\".format(\n",
    "                str(phase),\n",
    "                str(epoch_loss),\n",
    "                str(i),\n",
    "                str(int(time() - tic))\n",
    "            )\n",
    "            my_log = open(log_file, 'a+')\n",
    "            my_log.write(loss_str)\n",
    "            if train_opts[\"verbose\"]:\n",
    "                print(loss_str)\n",
    "            if phase == 'train':\n",
    "                stats['train_losses'].append(epoch_loss)\n",
    "                stats['train_losses_epochs'].append(i)\n",
    "                train_history['loss'].append(epoch_loss)\n",
    "            else:\n",
    "                val_meanIoU /= n_iter\n",
    "                val_history['loss'].append(epoch_loss)\n",
    "                val_history['mean_IoU'].append(val_meanIoU)\n",
    "                stats['val_losses'].append(epoch_loss)\n",
    "                stats['val_ious_epochs'].append(i)\n",
    "\n",
    "                scheduler.step(epoch_loss)\n",
    "                text = \"\\nVal meanIoU: {}\".format(str(val_meanIoU))\n",
    "                my_log = open(log_file, 'a+')\n",
    "                my_log.write(text)\n",
    "                if train_opts[\"verbose\"]:\n",
    "                    print(\"Val meanIoU: \" + str(val_meanIoU))\n",
    "                is_best = False\n",
    "                if val_meanIoU > stats['best_val_iou']:\n",
    "                    n_early_stopping = 0\n",
    "                    is_best = True\n",
    "                    stats['best_val_iou'] = val_meanIoU\n",
    "                    stats['best_val_epoch'] = i\n",
    "\n",
    "                else:\n",
    "                    n_early_stopping += 1\n",
    "\n",
    "                checkpoint = {\n",
    "                    'params': params,\n",
    "                    'epoch': i,\n",
    "                    'model': framework.model.state_dict(),\n",
    "                    'optimizer': framework.optimizer.state_dict(),\n",
    "\n",
    "                }\n",
    "                for k, v in stats.items():\n",
    "                    checkpoint[k] = v\n",
    "                saver.save(state=checkpoint, is_best=is_best,\n",
    "                           checkpoint_name='checkpoint')\n",
    "\n",
    "            if train_opts[\"early_stopping\"] and n_early_stopping > train_opts[\"early_stopping_patience\"]:\n",
    "                text = \"\\nEarly stopping on epoch: \" + str(i)\n",
    "                my_log = open(log_file, 'a+')\n",
    "                my_log.write(text)\n",
    "                if (train_opts[\"verbose\"]):\n",
    "                    print(\"Early stopping on epoch: \" + str(i))\n",
    "                break\n",
    "        sys.stdout.flush()\n",
    "    if train_opts[\"verbose\"]:\n",
    "        print(\"Done training\")\n",
    "    my_log = open(log_file, 'a+')\n",
    "    my_log.write(\"\\nDone training\")\n",
    "    saveLoss(train_history['loss'], val_history['loss'], backup_dir, \"loss_figure\")\n",
    "    saveLoss(train_history['loss'], val_history['loss'], train_dir, \"loss_figure\")\n",
    "    return framework, train_history, val_history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
